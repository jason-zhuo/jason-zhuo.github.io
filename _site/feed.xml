<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jaosonzhuo&#39;s blog</title>
    <description>Jasonzhuo&#39;s blog</description>
    <link>http://jasonzhuo.com/</link>
    <atom:link href="http://jasonzhuo.com//feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Random forest clustering</title>
        <description>&lt;h3&gt;随机森林聚类（Random forest clustering）&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2015-05-23-randforest.png&quot; alt=&quot;image&quot; /&gt;
随机森林聚类分析&lt;/p&gt;

&lt;!-- more --&gt;


&lt;h3&gt;1.起因&lt;/h3&gt;

&lt;p&gt;网络上现存的很多资料都是关于随机森林的分类和回归分析，但很少有材料讲解随机森林的聚类分析过程。
随机森林以及随机森林的分类回归过程我就不做详细介绍了，你可以参考网络上的其他资料 [1]，[2], [3], [8]。&lt;/p&gt;

&lt;p&gt;分析随机森林聚类算法还有如下的原因：&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;GBDT和随机森林在ESL书里面说是目前最优的两种算法&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;然后呢，最近也在研究一些新的聚类算法，就顺带研究一些随机森林是如何用了聚类的吧。&lt;/p&gt;

&lt;h3&gt;2.随机森林聚类&lt;/h3&gt;

&lt;p&gt;随机森林聚类算法的最核心思想：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 将非监督学习转换为监督学习&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. 相似度矩阵的计算&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;合成数据集（synthetic dataset）中包括的样本是通过样本合成算法产生新的样本的集合。最常用的就是合成算法就是生成和原始数据集（Orignial dataset）样本数量一致，相同特征的集合。&lt;/p&gt;

&lt;p&gt;举个网上的例子[7]来说吧：
假设有两个特征\(x_1\),\(x_2\).其中，\(x_1\)是连续变量服从\(Normal(0,1)\),\(x_2\)是0，1分布。一种合成数据的方法是根据每个特征的分布进行估计，值得注意的是随机生成的数据是各自独立的。另外一种合成方法是根据样本的概率进行随机选择，例如在样本中\(P(male)=0.4\),\(P(female)=0.6\)，那么合成的\(x_1\)的值就从原始数据集里面随机选择一个，合成的\(x_2\)的值就按照上述概率生成0或1。&lt;/p&gt;

&lt;p&gt;新的训练样本集合多了一个新的特征，该特征用来区分该样本是合成的还是原始的，用二进制表示即可。&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;新的训练样本集合（多一个类标签特征）=合成样本数据集合+原始数据集合&lt;/p&gt;&lt;/blockquote&gt;

&lt;h4&gt;2.1相似度矩阵&lt;/h4&gt;

&lt;p&gt;随机森林在建模的同时，还提供了样本相似性度量，即相似度矩阵(简记为 Prox 矩阵)。当用一棵树对所有数据进行判别时，这些数据最终都将达到该树的某个叶节点上.可以用两个样本在每棵树的同一个节点上出现的频率大小，来衡量这两个样本之间的相似程度，或两个样本属于同一类的概率大小。&lt;/p&gt;

&lt;p&gt;Prox矩阵\(P=p_{ij} \)生成过程如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;对于样本数为N的训练集合，首先生成一个\(N\times N\)的矩阵，\(p_{ii}=1\)，其他元素为0。&lt;/li&gt;
&lt;li&gt;对于任意两个样本\(x_i\),\(x_j\),若他们出现在生成的同一棵树上的同一个叶节点上，则$$p[i][j]= 1+p[i][j]$$&lt;/li&gt;
&lt;li&gt;重复上述过程直到m棵树全部生成，得到相应的矩阵&lt;/li&gt;
&lt;li&gt;进行归一化处理$$p[i][j]= \frac{p[i][j]}{N}$$&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;在随机森林进行聚类的过程中，运用到到了两个样本之间的相似度进行计算。我们知道在聚类算法中存在很多衡量两个样本之间距离的方法，欧几里得距离等等。但是在随机森林中的距离是如下计算的[5]:&lt;/p&gt;

&lt;p&gt;$$DISSIM[i][j]= \sqrt{1-p[i][j]}$$&lt;/p&gt;

&lt;h4&gt;2.2随机森林聚类计算过程&lt;/h4&gt;

&lt;p&gt;随机森林聚类算法：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;生成合成样本集合&lt;/li&gt;
&lt;li&gt;生成新的带类新标签的训练集合N，样本只包括两类：合成的数据，原始的数据&lt;/li&gt;
&lt;li&gt;根据N生成相似度矩阵P&lt;/li&gt;
&lt;li&gt;将P中被我们标记为合成数据的行和列删除&lt;/li&gt;
&lt;li&gt;运用其他聚类算法进行聚类&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;为啥我们要生产合成数据集，然后还要将其加入原始训练集合呢？我直观地认为直接在原始数据集上算相似性不就ok啦。后来我反应过来，但是原始数据是不带类标签的（非监督学习）。产生合成数据集的目的就是和原始数据进行类标记，将非监督学习转换为监督学习。&lt;/p&gt;

&lt;p&gt;步骤5中居然采用还是其他的聚类算法，只不过替换了距离测量方法，这点感觉有点那个啥&lt;img src=&quot;/assets/smilies/30.gif&quot; id=&quot;similey&quot;&gt;。&lt;/p&gt;

&lt;h4&gt;2.3随机森林聚类应用&lt;/h4&gt;

&lt;p&gt;文献[3]和文献[4]主要是用随机森林对医疗疾病属性的聚类，文献[3][4]用的是PAM（Partitioning around medoids）聚类算法。
随机森林的Prox矩阵可以作为多个基于不相似度聚类算法的输入，例如文献[5]中同样利用的是K-Medoids聚类算法PAM。作者将其应用到网络流量的聚类上，还比较创新。&lt;/p&gt;

&lt;h4&gt;2.4随机森林聚类Case study&lt;/h4&gt;

&lt;p&gt;利用R语言中的函数&lt;code&gt;rfClustering(model,noClusters=4)&lt;/code&gt;进行聚类分析，这个例子中没有体现出合成数据集合的生成的，因为iris数据集是带类标签的。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;set&amp;lt;-iris&lt;/code&gt; 载入iris数据集，iris数据集是带类标签的&lt;/li&gt;
&lt;li&gt;&lt;code&gt;md&amp;lt;-CoreModel(Species ~., set,model=&quot;rf&quot;,rfNoTrees=30)&lt;/code&gt; 利用随机森林得到模型，模型md中包括了相似度矩阵&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mdCluster&amp;lt;-rfClustering(md,3)&lt;/code&gt;聚成3类&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;code&gt;rfClustering&lt;/code&gt;这个函数根据作者介绍，内在是调用的PAM聚类算法的。&lt;/p&gt;

&lt;p&gt;聚类结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2015-05-23rfresult.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;参考文献&lt;/h3&gt;

&lt;p&gt;[1]&lt;a href=&quot;http://www.cnblogs.com/leftnoteasy/archive/2011/03/07/random-forest-and-gbdt.html&quot;&gt;http://www.cnblogs.com/leftnoteasy/archive/2011/03/07/random-forest-and-gbdt.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2]&lt;a href=&quot;http://blog.sciencenet.cn/blog-661364-615921.html&quot;&gt;http://blog.sciencenet.cn/blog-661364-615921.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3]&lt;a href=&quot;http://blog.csdn.net/songzitea/article/details/10035757&quot;&gt;http://blog.csdn.net/songzitea/article/details/10035757&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4]Shi T, Seligson D, Belldegrun A S, et al. Tumor classification by tissue microarray profiling: random forest clustering applied to renal cell carcinoma[J]. Modern Pathology, 2005, 18(4): 547-557.&lt;/p&gt;

&lt;p&gt;[5]Shi T, Horvath S. Unsupervised learning with random forest predictors[J]. Journal of Computational and Graphical Statistics, 2006, 15(1).&lt;/p&gt;

&lt;p&gt;[6]Wang Y, Xiang Y, Zhang J. Network traffic clustering using Random Forest proximities[C]//Communications (ICC), 2013 IEEE International Conference on. IEEE, 2013: 2058-2062.&lt;/p&gt;

&lt;p&gt;[7]&lt;a href=&quot;http://stats.stackexchange.com/questions/92725/unsupervised-random-forest-using-weka&quot;&gt;http://stats.stackexchange.com/questions/92725/unsupervised-random-forest-using-weka&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[8]&lt;a href=&quot;http://www.zilhua.com/629.html&quot;&gt;http://www.zilhua.com/629.html&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 23 May 2015 00:00:00 +0800</pubDate>
        <link>http://jasonzhuo.com///random-forest-clustering/</link>
        <guid isPermaLink="true">http://jasonzhuo.com///random-forest-clustering/</guid>
      </item>
    
      <item>
        <title>Software Define Network</title>
        <description>&lt;h3&gt;软件定义网络初探&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2015-05-14SDN1.png&quot; alt=&quot;image&quot; /&gt;
软件定义网络Software Define Network(SDN:Still don&#39;t know)初探笔记，以及Mininet原理分析&lt;/p&gt;

&lt;!-- more --&gt;


&lt;h3&gt;软件定义网络的定义&lt;/h3&gt;

&lt;p&gt;如果将网络中的所有网络设备视为被管理的资源，那么就像操作系统一样，软件定义网络SDN提供了同样的管理视图和编程接口。这样基于SDN这个平台，用户可以开发各种应用程序，通过软件来定义逻辑上的网络拓扑，以满足对网络资源的不同需求，二维无需关系底层网络的拓扑结构。&lt;/p&gt;

&lt;h3&gt;SDN交换机与控制器&lt;/h3&gt;

&lt;p&gt;SDN交换机只负责网络高速转发，保存的用于转发决策的转发表信息来自控制器，&lt;strong&gt;SDN交换机需要在远程控制器的管控下工作&lt;/strong&gt;，与之相关的设备状态和控制指令都需要经由SDN的南向接口传达，从而实现集中化统一管理。控制指令标准和状态需要满足SDN协议规范。
下图说明了SDN与交换机的工作流程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2015-05-15sdn2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;控制器目前有很多，根据知乎网友的推荐[link][http://www.zhihu.com/question/22599089], 控制器如果选择Python 的话，推荐 POX 或者 Ryu，更推荐 Ryu 一些，Java 的话就是 Floodlight 了。&lt;/p&gt;

&lt;h3&gt;术语区分&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Mininet&lt;/strong&gt;: 主要是虚拟出Openflow交换机以及host节点，并且可以自定义拓扑结构，是一个网络仿真平台。支持Openflow，OpenvSwitch等软件定义网络布局。
&lt;strong&gt;Open vSwitch（OVS）&lt;/strong&gt;:是由 Nicira Networks 主导的，运行在虚拟化平台（例如 KVM，Xen）上的虚拟交换机。
&lt;strong&gt;Opendaylight（ODL）&lt;/strong&gt;: 属于控制器的一种，开源项目，整体SDN解决方案，包含一系列组件，支持多种协议包括了openflow。是现在主流的控制器项目，功能比较完善
&lt;strong&gt;floodlight&lt;/strong&gt;: 属于控制器的一种，开源项目，文档齐全，图形化界面管理。简而言之，Floodlight提供了用户友好的图形化界面，来控制管理支持Openflow协议的交换机。
&lt;strong&gt;Openflow&lt;/strong&gt;: 是用于管理交换机流表的协议，起源于斯坦福大学的Clean Slate项目组，属于SDN协议的一种（其他的例如ForCES、PCE-P等等）。Openflow应用最广，现已成为了SDN的代言词。OpenFlow协议是描述控制器和交换机之间交互信息的南向接口标准。控制器和交换机之间通过这SDN协议进行连接建立，流表下发和信息交换，实现对网络中所有OpenFlow交换机的控制。&lt;/p&gt;

&lt;h3&gt;私有云与SDN的关系&lt;/h3&gt;

&lt;p&gt;私有云(Private Clouds)是为特定客户单独使用而构建的一个资源服务网络。特定用户拥有基础设施，并可以控制在此基础设施上部署需求的应用程序和服务。私有云的核心属性是专有资源。&lt;/p&gt;

&lt;p&gt;网络是私有云中的瓶颈问题。现在，服务器和存储技术已经发展成共享资源，云管理员可以自由地调用这些资源，但是网络却仍然是手动的。为了提高灵活性，私有云网络必须进行虚拟化，而软件定义网络（SDN）是一个性价比不错的方法。&lt;/p&gt;

&lt;p&gt;根据&lt;a href=&quot;https://www.opennetworking.org/solution-brief-how-openflow-based-sdn-transform-private-cloud&quot;&gt;ONF&lt;/a&gt;介绍，SDN是私有云的基础。SDN使得私有云可以分享设备资源，按需分配，自动操作，处理动态变化的事务更加灵活有效，最大化资源利用。&lt;/p&gt;

&lt;h3&gt;Mininet运行原理&lt;/h3&gt;

&lt;p&gt;Mininet通过Linux内置的Network Namespace来达到主机之间通信的隔离效果。这个Namespace和C++中的Namespace感觉差不多，不过C++Namespace达到的效果是函数的隔离。我觉得这篇blog介绍Linux Network namespace比较清楚，&lt;a href=&quot;http://neokentblog.blogspot.hk/2014/07/linux-network-namespace.html&quot;&gt;Network Namespace 介绍&lt;/a&gt;,通过这个介绍，Mininet理解起来就方便多了。&lt;/p&gt;

&lt;p&gt;在Mininet中我们不单可以在主机上面运行ping命令，每一条 Linux下的命令或者程序都可以在 Mininet 中的虚拟主机中运行。但是每个虚拟主机 h1，h2，s1三个进程列表是完全相同的。其实完全可以做到各个主机完全独立，就想 LXC 那样，但是目前 Mininet 并没有这么做。在 Mininet 中所有的进程都放在 root 下面，这样你可以在 Linux的 shell 中直接用kill或者ps这些命令查看或者杀死进程。&lt;a href=&quot;http://segmentfault.com/a/1190000000669218&quot;&gt;参考外链&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://ww4.sinaimg.cn/large/65c83a2bjw1dwmvastgo4j.jpg&quot; alt=&quot;Mininet原理&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;其它&lt;/h3&gt;

&lt;p&gt;通过mininet可以在本机迅速搭建任意拓扑结构的虚拟网络。然后利用控制器可以控制和管理所构建的虚拟网络，增加设备，删除设备等等。&lt;/p&gt;

&lt;p&gt;最简单的配置就是只有一台主机即可，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2015-05-15sdn3.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当然复杂一点可以利用多台主机，比如这样：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2015-05-15SDN4.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最近实验室采购设备，调研至此感觉SDN好像不需要特殊设备呢？我们只需要在不同host上运行不同的程序，甚至不同的操作系统，以方便网络安全实验。不过现在有很多厂家在做SDN控制器，还有支持Openflow协议的交换机，但都还不成熟。目前业界尚未发布完全符合 OpenFlow 协议规范的芯片，所以说感觉没必要买一些不成熟的产品。就多买几台性能还行的服务器，交换机，其余硬件资源没必要，在剩下的就是手动搭建工作了。&lt;/p&gt;
</description>
        <pubDate>Thu, 14 May 2015 00:00:00 +0800</pubDate>
        <link>http://jasonzhuo.com///sdn/</link>
        <guid isPermaLink="true">http://jasonzhuo.com///sdn/</guid>
      </item>
    
      <item>
        <title>Encrypted Traffic identification</title>
        <description>&lt;p&gt;&lt;img src=&quot;/assets/images/2015-05-11enflow2.png&quot; alt=&quot;image&quot; /&gt;
2015加密流量检测论文阅读笔记，持续更新（last update 2015.5.20）&lt;/p&gt;

&lt;!-- more --&gt;


&lt;h4&gt;目前还有效的加密流量识别方法&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;基于端口号的，局限性很大但某些场景仍然有效。&lt;/li&gt;
&lt;li&gt;基于内容签名的。有些加密协议有固定特殊的内容特征。&lt;/li&gt;
&lt;li&gt;基于流特征的。加密协议在进行密钥协商时具有特殊过程。&lt;/li&gt;
&lt;li&gt;基于主机行为的。从主机行为来看加密协议的建立过程，局限性仍然很大。&lt;/li&gt;
&lt;/ol&gt;


&lt;hr /&gt;

&lt;h4&gt;论文[1]作者的方法&lt;/h4&gt;

&lt;p&gt;上述方法的局限性较大。论文[1]中作者采用了随机度测试的方法来对加密流量进行识别。首先作者利用了\(l_{1}-norm\) regularized 逻辑斯特回归来选择&lt;strong&gt;sparse&lt;/strong&gt;特征（特征中有很多0值），然后利用了ELM来对加密流量进行识别，选择ELM的原因是其具有更好的识别效果和更快的识别速度。&lt;/p&gt;

&lt;p&gt;作者在论文[1]中利用随机度测试方法获取了188维度的特征，然后利用一范数正则化方法对特征进行降维。最后再利用ELM学习算法，对加密流量进行识别。&lt;/p&gt;

&lt;p&gt;识别效果和支持向量数据描述(support vector data description)SVDD以及GMM方法进行了对比。可见作者采用了one-class分类。最后的结果是识别率大概在80%左右。&lt;/p&gt;

&lt;h4&gt;随机度测试与加密方法&lt;/h4&gt;

&lt;p&gt;如何衡量加密算法的强弱好坏呢。有一种方法就是加密密文需要通过一定的随机度测试，输出的密文需要是随机的，或者近似随机的，这样的加密效果才好。衡量随机度的参数P-value越大则随机的可能性越高。参考：&lt;a href=&quot;http://www.zhihu.com/question/20222653&quot;&gt;知乎：如何评价一个伪随机数生成算法的优劣&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;下图比较形象的说明了随机数测试的问题&lt;a href=&quot;https://www.random.org/analysis/&quot;&gt;cited from https://www.random.org/analysis/ &lt;/a&gt;
&lt;img src=&quot;https://www.random.org/analysis/dilbert.jpg&quot; alt=&quot;Cited &quot; /&gt;
现在随机度测试的方法很多，如：NIST test set, DiEHARD test set等等，其中以美国国家标准与技术研究所的NIST最为著名：&lt;a href=&quot;http://csrc.nist.gov/groups/ST/toolkit/rng/documentation_software.html&quot;&gt;NIST传送门&lt;/a&gt;，&lt;a href=&quot;http://blog.csdn.net/Tom_VS_Jerry/article/details/26086099&quot;&gt;NIST安装过程介绍&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;NIST SP800-22 测试标准包含15个测试项，每个测试项都是针对被测序列的某一特性进行检测的，如下图所示。图片引用自[2]&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2015-05-11enflow.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h4&gt;特征提取与选择&lt;/h4&gt;

&lt;p&gt;作者在文中利用NIST测试套件，通过不同的参数调节产生不同的测试小项，总共提取了188维度的特征。然后作者利用稀疏特征提取(Sparse Feature selection)。并在逻辑斯特回归中加入了1范数罚参。&lt;/p&gt;

&lt;h4&gt;ELM 简介&lt;/h4&gt;

&lt;p&gt;传统的SVM和神经网络需要人们进行干预，学习速度较慢，学习泛化能力也比较差。极限学习机具有较快的学习速度以及良好的泛化性能。然而，它的性能还可以得到很大提高，主要基于两个原因[3]：(1)极限学习机网络中的隐层节点可以减少；(2)网络参数不必每次都调节。&lt;/p&gt;

&lt;p&gt;我感觉ELM和传统神经网络学习过程中最大的区别就在于如何求解最小化损失函数。传统的神经网络在学习过程中，学习算法需要在迭代过程中调整所有参赛。而在ELM算法中，直接通过求H的广义逆矩阵，输出权重\(\beta\)就可以被确定。&lt;/p&gt;

&lt;p&gt;为啥不需要调节参数了呢，原来Huang 已经证明了具有随机制定的输入权值、隐层阈值和非零激活函数的单隐层前馈神经网络可以&lt;strong&gt;普遍近似&lt;/strong&gt;任何具有紧凑输入集的连续函数。由此可以看出，输入权值和隐层阈值可以不必调节[3]。&lt;/p&gt;

&lt;p&gt;另外可以参考&lt;a href=&quot;http://blog.csdn.net/google19890102/article/details/18222103&quot;&gt;ELM算法简介&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;以及&lt;a href=&quot;http://www.ntu.edu.sg/home/egbhuang/&quot;&gt;ELM intro&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;还有&lt;a href=&quot;http://blog.csdn.net/itplus/article/details/9277721&quot;&gt;ELM算法基础&lt;/a&gt;&lt;/p&gt;

&lt;h4&gt;论文[6]阅读笔记&lt;/h4&gt;

&lt;p&gt;作者在文章中介绍了加密流量识别的基本情况，强调了最近的进展和未来的发展可能会遇到的挑战。文章中指出，加密流量类型主要集中在：SSH，VPN，SSL,加密P2P，加密VoIP，匿名网络流量。&lt;/p&gt;

&lt;p&gt;仅仅粗粒度区分加密和非加密流量是远远不够的，现实世界迫切需要的是从加密中获取应用层类型。这显然是相当复杂的工作，许多方法的综合运用才可能达到该目的。另外，协议混淆（traffic obfuscation）和流量变形（traffic morph）可以达到绕过基于机器学习的统计分类的效果，同样是未来的挑战之一。论文没有开放下载，只读了其中能看到的部分，就已经读到的内容来看，感觉文章综述很一般。&lt;/p&gt;

&lt;h3&gt;SSL/TLS应用层流量识别&lt;/h3&gt;

&lt;h4&gt;1.论文[4]阅读笔记&lt;/h4&gt;

&lt;p&gt;在未加密情况下识别应用层类型是比较成熟的，然而在加密情况下识别就相对困难许多。&lt;/p&gt;

&lt;p&gt;作者在文章中提出了使用随机指纹（&lt;em&gt;stochastic fingerprints&lt;/em&gt;）来识别SSL/TLS会话过程中的应用类型。指纹是基于一阶马尔可夫链的，然后马尔可夫链的参数是通过训练集合学习得到的。由于参数的不同性，该方法能有效的检测出应用层类型，以及异常的SSL会话过程。&lt;/p&gt;

&lt;p&gt;该方法和一些其他的SSL指纹识别方法比较类似，也是利用SSL/TLS握手过程中的头部信息。不同之处在于作者利用的是基于马尔可夫链随机指纹，将不同应用层类型的SSL/TLS握手过程的状态转移形成带有不同参数的马尔科夫状态转移链。作者在论文中对12项常用的SSL类型进行了建模：例如PayPal,Twitter,Skype等等。&lt;/p&gt;

&lt;h4&gt;2.论文[5]阅读笔记&lt;/h4&gt;

&lt;p&gt;传统的基于载荷的和机器学习的方法给系统造成的负载较大。作者提出了利用基于指纹和统计分析的混合方法来解决该问题。作者首先使用指纹来检测出SSL/TLS，然后再利用统计分析来找出确定的应用层类型。实验结果表明，该方法能够99%识别SSL/TLS流量，并达到F-score为94.52%的应用层识别效果。&lt;/p&gt;

&lt;p&gt;作者识别SSL/TLS流量的方法主要还是基于流量关键字段特征，这点和普通方法没区别。作者将SSL/TLS流量识别出来之后，又用了贝叶斯方法来对加密流的特征进行学习，统计特征包括：平均包长度，最大最小包长度，平均包到达间隔时间，流持续时间，流所包括的包数量。总体感觉创新不是很大。&lt;/p&gt;

&lt;h4&gt;参考文献&lt;/h4&gt;

&lt;p&gt;[1]Meng J, Yang L, Zhou Y, et al. Encrypted Traffic Identification Based on Sparse Logistical Regression and Extreme Learning Machine[M]//Proceedings of ELM-2014 Volume 2. Springer International Publishing, 2015: 61-70.&lt;/p&gt;

&lt;p&gt;[2]侯佳音, 萧宝瑾. 随机数测试标准与随机数发生器性能的关系[J]. 2012.&lt;/p&gt;

&lt;p&gt;[3]王建功. 基于极限学习机的多网络学习[J]. 2010.&lt;/p&gt;

&lt;p&gt;[4]Korczynski M, Duda A. Markov chain fingerprinting to classify encrypted traffic[C]//INFOCOM, 2014 Proceedings IEEE. IEEE, 2014: 781-789.&lt;/p&gt;

&lt;p&gt;[5]Sun G L, Xue Y, Dong Y, et al. An novel hybrid method for effectively classifying encrypted traffic[C]//Global Telecommunications Conference (GLOBECOM 2010), 2010 IEEE. IEEE, 2010: 1-5.&lt;/p&gt;

&lt;p&gt;[6]Cao Z, Xiong G, Zhao Y, et al. A Survey on Encrypted Traffic Classification[M]//Applications and Techniques in Information Security. Springer Berlin Heidelberg, 2014: 73-81.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Written with &lt;a href=&quot;https://stackedit.io/&quot;&gt;StackEdit&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
</description>
        <pubDate>Mon, 11 May 2015 00:00:00 +0800</pubDate>
        <link>http://jasonzhuo.com///encrypted-traffic-identification/</link>
        <guid isPermaLink="true">http://jasonzhuo.com///encrypted-traffic-identification/</guid>
      </item>
    
      <item>
        <title>Botnet detection</title>
        <description>&lt;p&gt;&lt;img src=&quot;/assets/images/2015-05-08botnet.png&quot; alt=&quot;image&quot; /&gt;
Botnet检测论文阅读笔记&lt;/p&gt;

&lt;!-- more --&gt;


&lt;h4&gt;僵尸网络检测方法面临的问题&lt;/h4&gt;

&lt;p&gt;和流量识别所面临的问题类似[1]，僵尸网络的检测同样也缺乏公开可用的测试数据集合通用的测试评估方法。在论文[2]中，作者提出了僵尸网络检测面临的问题：原有僵尸网络检测论文都只是提出了一种新方法，但是都没有做横向对比。其原因主要是因为分享包含僵尸网络流量数据比较困难，缺乏好的数据集，缺乏科学有效的对比方法等。&lt;/p&gt;

&lt;p&gt;作者在论文[2]中首次提出了他们的解决办法，并对3种常见的僵尸网络检测手段在自己收集整理的数据集合上做了横向对比。作者还将数据集合公开出来，极大的方便了其他研究人员的继续研究------&lt;a href=&quot;http://mcfp.weebly.com/the-ctu-13-dataset-a-labeled-dataset-with-botnet-normal-and-background-traffic.html&quot;&gt;数据集传送门&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;原有的论文都是自己提出了一种方法后，自己搜集了一些数据集进行测试。这些数据集往往很难获取，数据集合的真实性也难以保证和真实网络环境类似。同时，自己构造的数据集很难和其他方法进行对比。（不同的方法针对的数据集特征可能会大相径庭）除了数据集的问题之外，很多僵尸检测的论文中的评价指标仅局限于FPR，或者使用的是不同的评价定义方式，这给方法之间的评比造成困难。&lt;/p&gt;

&lt;h4&gt;1. CAMNEP&lt;/h4&gt;

&lt;p&gt;CAMNEP(Cooperative Adaptive Mechanism for NEtwork Protection) 是一个基于异常检测的网络行为的分析系统。系统包括了state of art的异常检测方法。
主要包括3部分：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;异常检测器： 通过多种异常检测模块，对网络行为进行分析&lt;/li&gt;
&lt;li&gt;信任模型：上一个输出的结果会和信任模型进行对比。信任模型会将Netflow根据其异常值和代表的事件类型聚集为不同类别。并持续对异常值进行更新来达到减少误报率。&lt;/li&gt;
&lt;li&gt;异常聚集器：结果汇总，对每个异常检测器的判定结果加权平均等。&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;CAMNEP利用NetFlow分析网络异常流量也存在一些限制条件，如需要网络设备对NetFlow的支持，需要分析NetFlow数据的工具软件，需要网络管理员准确区分正常流量数据和异常流量数据等。&lt;/p&gt;

&lt;h5&gt;1.1异常检测模块&lt;/h5&gt;

&lt;p&gt;下面介绍的异常检测模块是经过对原来算法的改进或者修改实现的，可能会和原来论文中的方法有差异。
&lt;strong&gt;MINDS&lt;/strong&gt;[3]，一个入侵检测模块，提取的特征包括：1.相同源IP地址发出的Netflow数，2.到达相同Host的Netflow数，3.从相同端口号到达相同Host的Netflow数，4.从相同Host到达相同端口号的Netflow数. 某种情况下（Context）下的异常值，为上述四个特征到正常样本的距离。最后的Global distance是各个Context下异常值的sum of their squares.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Xu et al. 2005&lt;/strong&gt; 提出的方法是将来自同一个源IP地址的Netflow进行特征提取。特征包括：1. 正则化后的源端口熵值（Normalized entropy of the source ports），2. 正则化后的目的IP地址熵值，3. 正则化后的目的端口熵值。某种情况下（Context）下的异常值，为上述3个特征到正常样本的距离。最后的distance同样是各个Context下异常值的sum of their squares.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lakhina volume&lt;/strong&gt; 原文章是来自Sigcomm的文章，针对的是Network-wide的异常检测。在[1]中作者修改了其中一部分，其主要思想是将来自同一个源IP地址的数据流用PCA方法分为正常流和非正常流，因为正常流占了绝大多数成分而异常流只存在少部分。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lakhina entropy&lt;/strong&gt; 基于上述PCA的思想，但是采用了和xu et al.类似的特征。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TAPS 2006&lt;/strong&gt; 与上述方法都不相同。该方法针对的是横向和纵向端口扫描。该方法的基本思想还是通过提取特征，然后设置特征阈值。超过一定的阈值则判断为扫描行为。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;KGB 2012&lt;/strong&gt; 基于的是  Lakhina 的工作，也是利用的PCA来分解每个源IP产生的特征向量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Flag&lt;/strong&gt; 和KGB方法类似，只不过输入的特征向量不同。Flag是基于来自同一个IP地址的TCP标志柱状图 。该检测器就是寻找一个连续的TCP标志异常组合。&lt;/p&gt;

&lt;h5&gt;1.2可信模型建立&lt;/h5&gt;

&lt;p&gt;CAMNEP的可信模型类似于Kmeans中的聚类。模型计算每个Netflow到每个可信簇类中心(Centroid)的距离。&lt;/p&gt;

&lt;h4&gt;2. BGlus&lt;/h4&gt;

&lt;p&gt;BGlus是基于行为的僵尸网络检测方法。其基本思想是先对已知的僵尸网络流量进行模型抽象，然后在网络上寻找相似的流量。
其基本步骤如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将Netflows按时间窗口进行分割&lt;/li&gt;
&lt;li&gt;将分割后的Netflows按照相同的源IP进行组合&lt;/li&gt;
&lt;li&gt;对不同的源IP流量进行聚类&lt;/li&gt;
&lt;li&gt;该步只针对训练阶段：对僵尸网络聚类进行ground truth 打标签&lt;/li&gt;
&lt;li&gt;该步只针对训练阶段：利用僵尸网络簇训练一个分类器。&lt;/li&gt;
&lt;li&gt;该步只针对测试阶段：利用分类器来检测聚类结果中的僵尸网络簇&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;关于作者在第二步中为什么这么做。作者假设这样做会产生新的patterns，可以帮助我们识别僵尸网络，这样做偏向于基于主机的行为分析。&lt;/p&gt;

&lt;p&gt;作者在BGlus中运用的是EM聚类算法（作者假设不同的流量产生于相同的分布）和JRIP分类算法。&lt;/p&gt;

&lt;h4&gt;3. BotHunter&lt;/h4&gt;

&lt;p&gt;BotHunter是基于状态序列的匹配方法。它有一个关联分析引擎来分析恶意软件当前的状态过程。检测的特征过程包括：inbound scanning, exploit usage, egg download, outbound bot coordination dialog, outbound attack propagation.&lt;/p&gt;

&lt;p&gt;BotHunter是经过修改过的Snort软件。主要增加了两个插件，一个是SCADE(statistical scan anomaly detection engine) ,另外一个是SLADE(statistical payload anomaly detection engine)&lt;/p&gt;

&lt;p&gt;下面穿插对比一下几个检测器：
&lt;strong&gt;Bothunter&lt;/strong&gt;: Vertical Correlation. Correlation on the behaviors of single host.
&lt;strong&gt;Botsniffer&lt;/strong&gt;: Horizontal Correlation. On centralized C&amp;amp;C botnets
&lt;strong&gt;Botminer&lt;/strong&gt;: Extension on Botsniffer, no limitations on the C&amp;amp;C types.&lt;/p&gt;

&lt;h4&gt;4. 数据集构建&lt;/h4&gt;

&lt;p&gt;论文中作者构建的数据集具有以下特点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;是真实的僵尸网络程序，而不是仿真&lt;/li&gt;
&lt;li&gt;数据集中包括未知流量&lt;/li&gt;
&lt;li&gt;数据集中存在类标，方便训练和方法效果评估&lt;/li&gt;
&lt;li&gt;包括多种僵尸网络流量&lt;/li&gt;
&lt;li&gt;包括多个僵尸主机同时被感染的情况&lt;/li&gt;
&lt;li&gt;包括Netflow文件用来保护用户隐私&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;作者在一台虚拟主机上设置了僵尸网络程序，这台主机唯一产生僵尸网络流量。然后作者将该虚拟主机和校园网络桥接，并分别在虚拟主机上抓包和校园网络某一台路由器上抓包。虚拟主机产生的流量是用于做类标记的。作者相信最好的办法是抓真实攻击的数据包，因此作者并没有在互联网入口处设置过滤。这样做真的好吗？&lt;/p&gt;

&lt;p&gt;作者利用Argus软件将Pcap文件转换为Netflow文件。Netflow文件包括了以下一些字段：开始时间，结束时间，持续时间，源IP，目的IP,源端口，目的端口，目的IP，状态，SToS，总包数，总包大小。&lt;/p&gt;

&lt;h4&gt;5.对比结果&lt;/h4&gt;

&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;BClus&lt;/strong&gt; showed large FPR values on most scenarios but also large TPR.
The &lt;strong&gt;CAMNEP&lt;/strong&gt; method had a low FPR during most of the scenarios but at the expense of a low TPR.
The &lt;strong&gt;BotHunter&lt;/strong&gt; algorithm presented very low values during the whole scenario despite that there were ten bots being executed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt; 看来&lt;strong&gt;BotHunter&lt;/strong&gt;的检测效果在作者所做的实验中表现一般，因此作者在结论中评价也相对含蓄。&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;BotHunter method showed that in real environments it could still be useful to have blacklists of known malicious IP addresses&lt;/p&gt;&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;blockquote&gt;&lt;p&gt;Written with &lt;a href=&quot;https://stackedit.io/&quot;&gt;StackEdit&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;

&lt;h4&gt;参考文献&lt;/h4&gt;

&lt;p&gt;[1]Dainotti A, Pescape A, Claffy K C. Issues and future directions in traffic classification[J]. Network, IEEE, 2012, 26(1): 35-40.&lt;/p&gt;

&lt;p&gt;[2]An empirical comparison of botnet detection methods&quot; Sebastian Garcia, Martin Grill, Honza Stiborek and Alejandro Zunino. Computers and Security Journal,
Elsevier. 2014. Vol 45, pp 100-123. http://dx.doi.org/10.1016/j.cose.2014.05.011&lt;/p&gt;

&lt;p&gt;[3]Ertoz L, Eilertson E, Lazarevic A, Tan PN, Kumar V, Srivastava J, et al.
Minds-minnesota intrusion detection system. In: Next generation data mining. MIT Press; 2004. pp. 199e218.&lt;/p&gt;
</description>
        <pubDate>Fri, 08 May 2015 00:00:00 +0800</pubDate>
        <link>http://jasonzhuo.com///botnet-detection/</link>
        <guid isPermaLink="true">http://jasonzhuo.com///botnet-detection/</guid>
      </item>
    
      <item>
        <title>Shadowsocks in Lab</title>
        <description>&lt;p&gt;&lt;img src=&quot;https://dn-teddysun.qbox.me/wp-content/uploads/2015/shadowsocks_logo.png&quot; alt=&quot;image&quot; /&gt;
好多童鞋搞不清楚我在实验室搭建的Shadowsocks如何使用，在这里给你们科普一下，知道原理之后使用起来就更加顺心了，保证一口气科研就到天亮哦~&lt;/p&gt;

&lt;!-- more --&gt;


&lt;h4&gt;注明：以下高能内容转载自&lt;a href=&quot;http://vc2tea.com/whats-shadowsocks/&quot;&gt;vc2tea的博客&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;在很久很久以前，我们访问各种网站都是简单而直接的，用户的请求通过互联网发送到服务提供方，服务提供方直接将信息反馈给用户.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://vc2tea.com/public/upload/whats-shadowsocks-01.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后有一天，GFW 就出现了，他像一个收过路费的强盗一样夹在了在用户和服务之间，每当用户需要获取信息，都经过了 GFW，GFW将它不喜欢的内容统统过滤掉，于是客户当触发 GFW 的过滤规则的时候，就会收到 Connection Reset 这样的响应内容，而无法接收到正常的内容.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://vc2tea.com/public/upload/whats-shadowsocks-02.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;聪明的人们想到了利用境外服务器代理的方法来绕过 GFW 的过滤，其中包含了各种HTTP代理服务、Socks服务、VPN服务, &lt;strong&gt;Tor&lt;/strong&gt;, &lt;strong&gt;Freegate&lt;/strong&gt; … 其中以 ssh tunnel 的方法比较有代表性&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;首先用户和境外服务器基于 ssh 建立起一条加密的通道&lt;/li&gt;
&lt;li&gt;用户通过建立起的隧道进行代理，通过 ssh server 向真实的服务发起请求&lt;/li&gt;
&lt;li&gt;服务通过 ssh server，再通过创建好的隧道返回给用户&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;img src=&quot;http://vc2tea.com/public/upload/whats-shadowsocks-03.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由于 ssh 本身就是基于 RSA 加密技术，所以 GFW 无法从数据传输的过程中的加密数据内容进行关键词分析，避免了被重置链接的问题，但由于创建隧道和数据传输的过程中，ssh 本身的特征是明显的，所以 GFW 一度通过分析连接的特征进行干扰，导致 ssh 存在被定向进行干扰的问题。&lt;/p&gt;

&lt;p&gt;这时候&lt;strong&gt;shadowsocks&lt;/strong&gt;横空出世。简单看来，shadowsocks是将原来 ssh 创建的 Socks5 协议拆开成 server 端和 client 端，所以下面这个原理图基本上和利用 ssh tunnel 大致类似。&lt;/p&gt;

&lt;h4&gt;shadowsocks工作原理&lt;/h4&gt;

&lt;p&gt;1、6) 客户端发出的请求基于 Socks5 协议跟 ss-local 端进行通讯，由于这个 ss-local 一般是本机或路由器或局域网的其他机器，不经过 GFW，所以解决了上面被 GFW 通过特征分析进行干扰的问题&lt;/p&gt;

&lt;p&gt;2、5) ss-local 和 ss-server 两端通过多种可选的加密方法进行通讯，经过 GFW 的时候是常规的TCP包，没有明显的特征码而且 GFW 也无法对通讯数据进行解密&lt;/p&gt;

&lt;p&gt;3、4) ss-server 将收到的加密数据进行解密，还原原来的请求，再发送到用户需要访问的服务，获取响应原路返回&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://vc2tea.com/public/upload/whats-shadowsocks-04.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;截止目前，笔者所使用最流畅、最稳定的就是shadowsocks，一口气翻墙不费劲，以后再也不用操心翻墙了。传送门：&lt;a href=&quot;https://github.com/shadowsocks/shadowsocks&quot;&gt;shadowsocks下载地址&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;在我们实验室中，翻墙代理设置可以为网关的IP地址192.168.1.1，也可以为本地127.0.0.1地址。唯一区别就是上图中SS Local代理程序运行的位置不同，（刘博士懂了撒~）。在实验室环境中，童鞋们可以自己设置利用本机的代理，也可以使用阿江搭建在网关上的SS Local代理，效果一致。没有在实验室的童鞋就只能靠自己本地代理啦。最后使用的时候需要设置为Socks5代理类型就可以正常使用了。
&lt;img src=&quot;/assets/smilies/37.gif&quot; id=&quot;similey&quot;&gt;
(css inline 表情，深夜特别鸣谢刘博士)
&lt;img src=&quot;/assets/smilies/28.gif&quot; id=&quot;similey&quot;&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 25 Apr 2015 00:00:00 +0800</pubDate>
        <link>http://jasonzhuo.com///shadowsocks-in-lab/</link>
        <guid isPermaLink="true">http://jasonzhuo.com///shadowsocks-in-lab/</guid>
      </item>
    
      <item>
        <title>Botnet and fast flux</title>
        <description>&lt;p&gt;Botnet and fast flux 特征介绍；Botminer论文初看&lt;/p&gt;

&lt;!-- more --&gt;


&lt;h2&gt;Botnet and fast flux&lt;/h2&gt;

&lt;hr /&gt;

&lt;h3&gt;几个定义&lt;/h3&gt;

&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Round-Robin DNS (RRDNS) &lt;/strong&gt;* &lt;/dt&gt;
&lt;dd&gt;Round-robin的意思是循环的意思，顾名思义，这种DNS返回的A记录不只一个，返回的记录是一个列表，列表里面记录的先后顺序是循环出现的。&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Content Distribution Networks (CDN)&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;中文名叫内容分发网络，和RRDNS比较类似，不过返回的记录的TTL值相对RRDNS更低。CDN系统能够实时地根据网络流量和各节点的连接、负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。其目的是使用户可就近取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度。&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;&lt;em&gt;Fast-Flux Service Networks (FFSN)&lt;/em&gt;&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;FFSN更加创新地利用了RRDNS和CDN的上述特性，来降低恶意服务器被发现和关闭的概率。FFSN的特点下面会讨论。&lt;/dd&gt;
&lt;/dl&gt;

&lt;hr /&gt;

&lt;h3&gt;Fast flux特征&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;不重复的IP地址数量&lt;/strong&gt;：通常情况来说合法DNS查询不重复的IP地址为1~3个，而fast flux查询结果中会有5~6个，以确保至少有一个IP可以连接。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NS数量&lt;/strong&gt;：NS数量是指在单一次DNS 查询中所得到的NS （Name server）数量。客户端与DNS 主机进行查询时,可能透过快速变动网域技术掩护DNS 主机,因此NS Records 与NS 的A Records 可能有多笔记录,相较之下,合法的FQDN 其NS Records 与NS 的A Records比较少。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ASN数量与注册时间&lt;/strong&gt;：指对ASN进行查询时，主机使用的IP所属的ASN是否属于同一个单位。由于CDN主机使用的IP所属的ASN多属于同一个单位，而fast flux主机大多分散在世界各地，与CDN向比较之下，主机使用的IP所属的ASN属于不同单位。注册时间能够缩小选取范围。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Domain age&lt;/strong&gt;:指合法网站记录的TTL时间相对于恶意网站更长；恶意网站的FQDN与对应的IP记录不会长时间存留电脑，电脑必须时常进行DNS查询，以更新记录。RFC1912建议TTL最小为1~5天，这么长！而FFSN的TTL值一般小于600秒。但是一般不使用TTL值来判定FFSN，因为这样的误报率比较高，合法使用的CDN也会返回比较低的TTL值。因此TTL值一般用来区分FFSN/CDN和RRDNS.&lt;/li&gt;
&lt;/ol&gt;


&lt;h4&gt;常见僵尸网络检测程序&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt; Name        &lt;/th&gt;
&lt;th style=&quot;text-align:center;&quot;&gt;TYPE                       &lt;/th&gt;
&lt;th style=&quot;text-align:center;&quot;&gt;Protocols &lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;BotSniffer     &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt; centralized servers     &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt;   IRC,HTTP &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; BotHunter      &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt; structure independent  &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt;Protocol independent &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Botminer &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt; structure independent  &lt;/td&gt;
&lt;td style=&quot;text-align:center;&quot;&gt;    Protocol independent       &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;h3&gt;BotMiner 初看&lt;/h3&gt;

&lt;h5&gt;BotMiner的系统架构&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2015-04-19-botminer.png&quot; alt=&quot;Structure of Botminer&quot; /&gt;&lt;/p&gt;

&lt;h4&gt;论文中的一些定义&lt;/h4&gt;

&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;A平面&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;主要检测恶意行为模型,文章用Snort检测某主机的行为,主机的扫描行为用的是Bothunter的SCADE，下载地址：&lt;a href=&quot;http://www.bothunter.net/&quot;&gt;Cyber-TA.BotHunter Free Internet Distribution Page, 2008. &lt;/a&gt;。文章采用两种异常检测模式，一种是高频率异常扫描次数，另外一种是带加权的失败连接次数。文章作者为了检测恶意邮件，开发了一种&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;C平面&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;网络通信关系模型和流特征模型&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;AC跨平面关联&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;发现AC平面之间的某种关联关系，僵尸网络评分s(h)&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;C平面的聚类&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;  定义 C-flow 为一段时间E内具有相同源IP，目的IP和目的端口的网络流&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;&lt;strong&gt;C-flow的一些特征&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;FPH: the number of flows per hour.&lt;/li&gt;
&lt;li&gt;PPF: the number of packets per flow&lt;/li&gt;
&lt;li&gt;BPP: the average number of bytes per packets&lt;/li&gt;
&lt;li&gt;BPS: the average number of bytes per second&lt;/li&gt;
&lt;/ol&gt;


&lt;h4&gt;参考文献&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.usenix.org/legacy/event/sec08/tech/full_papers/gu/gu_html/&quot;&gt;[1]BotMiner: Clustering Analysis of Network Traffic for
Protocol- and Structure-Independent Botnet Detection&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 25 Apr 2015 00:00:00 +0800</pubDate>
        <link>http://jasonzhuo.com///Botnet%20and%20fast%20flux/</link>
        <guid isPermaLink="true">http://jasonzhuo.com///Botnet%20and%20fast%20flux/</guid>
      </item>
    
      <item>
        <title>Structure Risk Minimization,SRM</title>
        <description>&lt;p&gt;&lt;img src=&quot;/assets/images/2015-04-18-StatML.png&quot; alt=&quot;image&quot; /&gt;
本周学术交流，张老师给我们介绍了结构风险最小化原理，这篇博客对交流内容进行了精炼和总结。&lt;/p&gt;

&lt;!-- more --&gt;


&lt;h2&gt;结构风险最小化&lt;/h2&gt;

&lt;hr /&gt;

&lt;p&gt;基于数据的机器学习有2个方法，第1个是经典的统计估计方法，通过训练样本来估计参数值，代表是R.A Fisher 的统计理论（线性回归）。但我们经常做的预测真的&lt;strong&gt;靠谱&lt;/strong&gt;吗？答案是，不靠谱，因为我们在做预测的时候，引入了一个很强的假设条件———样本集要满足独立同分布条件（iid-independent identically distribulted）。&lt;/p&gt;

&lt;p&gt;第2个方法是V.Vapnik等人提出的统计学习理论。该理论也被称作VC理论，最重要的概念就是VC维。VC维~函数复杂度~是一个正整数（也叫做函数容量）。函数复杂度越大，预测效果越差。&lt;/p&gt;

&lt;p&gt;$$R_{exp}=\int L(y,f)p(x,y)dxdy \leq \frac{1}{m} \sum_i^{m} {(y_i-f(x_i))}^2 +\psi(\frac{V(f)}{m})$$&lt;/p&gt;

&lt;p&gt;其中\(V(f)\)就是函数VC维，m为样本个数。上式表明在样本一定的情况下，VC维越高，期望风险越大。&lt;/p&gt;

&lt;p&gt;统计学习理论-结构风险最小化SRM:&lt;br/&gt;
        $$期望风险&amp;lt;=经验风险 + 置信度$$&lt;/p&gt;

&lt;p&gt;这里简单介绍一下Vladimir Vapnik。Vladimir Vapnik是俄国人，1936年出生。1964年，他于莫斯科的控制科学学院获得博士学位。毕业后，他一直在该校工作直到1990年，这期间他作为不多（估计在国内可能有点那个），但是1991加入贝尔实验室之后，他在1995年发明了SVM。从此，他就出名了，2006年当上了美国科学院院士。
&lt;img src=&quot;/assets/smilies/16.gif&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;所谓的结构风险最小化就是在保证分类精度（经验风险）的同时，降低学习机器的 VC 维，可以使学习机器在整个样本集上的期望风险得到控制。&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;见图：
&lt;img src=&quot;http://img.my.csdn.net/uploads/201105/29/0_1306659245j5ZS.gif&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;张老师随后介绍了SVM中最著名的核方法。将低维度转化到高维度，计算复杂度却和低维度差不多。这太牛了，佩服Mercer。张老师补充到，这个是1911年提出来的（当时清王朝刚被推翻，国内可能无人潜心科研吧），之后Mercer的论文成为了睡美人，直到后来被Vapnik发现。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;核函数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$&amp;lt;\psi(x),\psi(y)&gt;=k(x,y)$$&lt;/p&gt;

&lt;p&gt;核函数的作用&lt;/p&gt;

&lt;p&gt;$$R^{n} \to H^{\infty}$$
(H为Hilbert空间)&lt;/p&gt;

&lt;p&gt;非线性问题&lt;strong&gt;一定&lt;/strong&gt;能够线性化&lt;/p&gt;
</description>
        <pubDate>Sat, 18 Apr 2015 00:00:00 +0800</pubDate>
        <link>http://jasonzhuo.com///structure-risk-minimizationsrm/</link>
        <guid isPermaLink="true">http://jasonzhuo.com///structure-risk-minimizationsrm/</guid>
      </item>
    
      <item>
        <title>Big data Short notes</title>
        <description>&lt;p&gt;Bigdata培训课程，听了一天，感觉听不大懂，工程细节上的东西太多了，而且自己这方面也刚刚起步，因此本文就稍微记一下我比较感兴趣的内容。&lt;/p&gt;

&lt;!-- more --&gt;


&lt;h3&gt;Spark Streaming&lt;/h3&gt;

&lt;blockquote&gt;&lt;p&gt;目前的大数据处理可以分为如下3个类型：&lt;/p&gt;&lt;/blockquote&gt;

&lt;ol&gt;
&lt;li&gt;复杂的批量数据处理：10min~数小时&lt;/li&gt;
&lt;li&gt;基于历史数据的交互式查询： 10sec~ 数分钟&lt;/li&gt;
&lt;li&gt;基于实时数据流的数据处理（Streaming data processing): 数百毫秒到数秒&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;除了Spark，流式计算计算系统比较有名的包括Twitter Storm和Yahoo S4。现在所提及的Storm主要是指Apache Storm ，Apache Storm的前身是 Twitter Storm 平台，目前已经归于 Apache 基金会管辖。Storm已经出现好多年了，而且自从2011年开始就在Twitter内部生产环境中使用，还有其他一些公司。而Spark Streaming是一个新的项目, 2013年开始。&lt;/p&gt;

&lt;p&gt;Spark的流式计算还是要弱于Storm的，作者在&lt;a href=&quot;http://www.csdn.net/article/2014-08-04/2821018&quot;&gt;这篇文章中&lt;/a&gt;认为互联网公司对于Storm的部署还是多于Spark。这篇文章对&lt;a href=&quot;http://blog.csdn.net/anzhsoft/article/details/38168025&quot;&gt;流式计算&lt;/a&gt;系统的设计考虑的一些要素进行了比较详细的讨论。这篇文章介绍了Storm和Streaming框架的&lt;a href=&quot;http://www.open-open.com/lib/view/open1426129553435.html&quot;&gt;对比&lt;/a&gt;. 如此说来，Storm在以后的项目中估计要用到&lt;img src=&quot;/assets/smilies/8.gif&quot; alt=&quot;image&quot; /&gt;.&lt;/p&gt;

&lt;p&gt;相对与&lt;strong&gt;Mapreduce&lt;/strong&gt;来说，Mapreduce的输入数据集合是静态的，不能动态变化。因此适合于离线处理。Mapreduce的使用场景包括，简单的网站pv,uv统计，搜索引擎建立索引，海量数据查找，复杂数据的分析和算法实现（聚类，分类，推荐，图算法等）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Yarn&lt;/strong&gt; 的提出，解决了多计算框架直接的数据无法共享问题，同时负责集群资源的统一管理和调度。&lt;/p&gt;

&lt;p&gt;运行在YARN上的计算框架：
1. 离线计算框架Mapreduce
2. DAG计算框架Tez
3. 流式计算框架Strom
4. 内存计算框架Spark&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Written with &lt;a href=&quot;https://stackedit.io/&quot;&gt;StackEdit&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
</description>
        <pubDate>Sat, 18 Apr 2015 00:00:00 +0800</pubDate>
        <link>http://jasonzhuo.com///big-data-course/</link>
        <guid isPermaLink="true">http://jasonzhuo.com///big-data-course/</guid>
      </item>
    
      <item>
        <title>hello world again</title>
        <description>&lt;p&gt;I&#39;m back!&lt;/p&gt;

&lt;!-- more --&gt;


&lt;p&gt;时隔了这么久没写过博客，感觉有点对不起起初建立博客的初衷。于是想把我的博客给恢复起来。今天尝试了向我的博客里面添加数学公式的方法：&lt;/p&gt;

&lt;h3&gt;添加行内公式&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;\\(公式\\)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;添加行间公式&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$$公式$$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例如行间公式：\(\sum_{i\to 2}^i\)&lt;/p&gt;

&lt;p&gt;$$\sum_{i\to 2}^i$$&lt;/p&gt;

&lt;p&gt;具体来说实现比较简单：
如果用Mou渲染Math公式，尝试在&lt;strong&gt;default.html&lt;/strong&gt;加上如下js，表示让Mou去加载Mathjax的脚本&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;script type=&quot;text/javascript&quot;
 src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&amp;gt;
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在试过上面的方法后，我还尝试了直接在mou编辑过程中加入上述代码：
&lt;img src=&quot;/assets/images/2015-04-16-mathequa.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;加入之后倒是可以一边编辑一边看到编辑结果，但是容易造成Mou在渲染过程中的卡顿，不推荐这样使用。&lt;/p&gt;

&lt;p&gt;编辑完成之后，在上传之前可以进行检查，把上述图中的代码加入就可以进行检查了。&lt;/p&gt;

&lt;p&gt;在此庆祝我的博客复活啦，以后就可以写写高大上的数学公式了~ 就这样了，碎觉碎觉，累死累活！&lt;/p&gt;

&lt;blockquote&gt;&lt;h2&gt;... in mathematics you didn&#39;t understand things, you just get used to them. --J.von.Newmann &lt;/h2&gt;&lt;/blockquote&gt;
</description>
        <pubDate>Wed, 15 Apr 2015 00:00:00 +0800</pubDate>
        <link>http://jasonzhuo.com///hello-world-again/</link>
        <guid isPermaLink="true">http://jasonzhuo.com///hello-world-again/</guid>
      </item>
    
      <item>
        <title>Big data Algorithm Report</title>
        <description>&lt;p&gt;&lt;img src=&quot;/assets/images/2014-12-1-Bigdata.jpg&quot; alt=&quot;image&quot; /&gt;
这篇主要讲的是周末听大数据讲座的听后感。&lt;/p&gt;

&lt;!-- more --&gt;


&lt;p&gt;大数据时代，我们每个人都在谈论大数据，每个人都可以说自己在研究大数据。但是真正懂大数据的还是只有真正的大神们。大数据设计的概念太大了，就和云计算差不多，涵盖的面也非常广泛，可以说是上到天文下到地理，从宏观的天体运动到微观的分子结构，简直无所不包。&lt;/p&gt;

&lt;p&gt;报告上半场是9点到12点，下半场是14点到18点。我听了上半场的上半部分和整个下半场。听完报告感觉都快虚脱了。。。各种听不懂，各种高大上~ 能听懂的都是前面几页PPT。真实台上一分钟，台下十年功啊！台上PPT的每一个图或者一个表，虽然只展示了不到1分钟，但其背后的付出都是可想而知的。我还发现大牛们的一个普遍规律，就是讲着讲着就冒一句英语，而且语速还不慢。简直让我们摸不着头脑。&lt;/p&gt;

&lt;h4&gt;大数据的4V特点:&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2014-12-1-big4.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这四个特点好像很多老师来做报告都要讲，不过都是简单地提了一下。&lt;/p&gt;

&lt;h4&gt;报告简单回忆&lt;/h4&gt;

&lt;h5&gt;1.Collective attention and Collective allocation&lt;/h5&gt;

&lt;p&gt;报告首先是由沈华伟老师给我们带来的Collective attention and Collective allocation. Collective attention主要是衡量一篇论文到底能获得多大关注度。Collective allocation是说的有些诺贝尔颁奖的时候，有些情况是颁发给论文的第1作者，但也有些情况是颁发给论文的第3或者第4作者。这个资源分配的问题就是Collective allocation问题，其主要思想是结合每个作者在该领域的引用文章的影响进行合理分配。&lt;/p&gt;

&lt;h5&gt;2. A query-based algorithm framework for dynamic data analysis&lt;/h5&gt;

&lt;p&gt;刘兴武老师介绍了一下动态处理大规模数据的方法。主要思想是用基于查询的方法来处理动态数据。&lt;/p&gt;

&lt;h5&gt;3.融合空间认知学的空间数据库研究&lt;/h5&gt;

&lt;p&gt;邵杰老师介绍了如何利用空间认知学上的研究思路来进行数据研究。空间认知学包括了地理学和认知心理学。传统的寻路算法都是考虑的是最近邻，最短路径等，然而，现在我们需要寻找最易到达邻。这一点还是很有研究意义的。&lt;/p&gt;

&lt;h5&gt;4.Learn to Hash for Big Data&lt;/h5&gt;

&lt;p&gt;李武军老师介绍了如何用Hash函数来处理数据。在大数据的前提下，Hash函数可以降维，提高处理效率，节约存储空间。李老师主要介绍了监督Hash学习方法，非监督Hash学习和多模态Hash学习方法。Hash学习和最近邻检索有着密切关系。&lt;/p&gt;

&lt;h5&gt;5.Big-data Machine Learning&lt;/h5&gt;

&lt;p&gt;林智仁老师给我们带来的是关于分布式的机器学习方法。林老师的讲解深入浅出，相对容易理解一些。林老师还形象地描述了做大数据的人，形容的相当形象。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2014-12-01-live.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Big data is like teenage sex, everyone talks about it, nobody really knows how to do it, everyone thinks everyone else is doing it, so everyone claims they are doing it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;传统的机器学习都是单机的，在处理大数据时效率很低，训练时间长，不能够让模型随着新增样本的变化而相应变化。考虑提高效率的方法，有（1）买一个超大RAM （2）Disk-level 机器学习 （3）GPU计算 （4）分布式机器学习。但是林老师也说了，不是所有的都可以用分布式来解决问题。分布式还会带来很多问题，例如同步，通信时间。原来的Ph.D学生都主要研究训练计算时间如何提高上去了，很少有人研究过在大数据情况下，如何快速载入大数据。&lt;/p&gt;

&lt;h5&gt;5.用物理观点看图挖掘问题&lt;/h5&gt;

&lt;p&gt;好不容易到了最后，本以为周涛老师会以幽默风趣的谈吐和深入浅出的讲解结束本次报告。但是，恰恰相反，到了很多人已经筋疲力尽的时候，周涛老师讲了他是如何用物理学上的方法解决网络链路预测问题的。他所提出的模型似乎很强大，比原来的牛文章里面的还要好。不过我没听懂，PPT上各种公式弄得我晕头转向。但是，周涛老师提到了用统计物理的方法来研究计算机问题，挺有启发的。&lt;/p&gt;

&lt;h5&gt;6.秘书问题与在线算法&lt;/h5&gt;

&lt;p&gt;孙晓明老师介绍了秘书问题和在线算法相关工作。在通常情况下，数据都是一个接着一个到达的，正如秘书来面试一样，是一个接着一个和面试官面试的。面试官如何在这种情况下选择最优的秘书，是在线算法需要解决的工作。秘书问题是多对一的问题，online matching是多对多的问题。这些问题有关动态分配和动态取最优解，比较有意思。&lt;/p&gt;
</description>
        <pubDate>Mon, 01 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://jasonzhuo.com///BigDatareport/</link>
        <guid isPermaLink="true">http://jasonzhuo.com///BigDatareport/</guid>
      </item>
    
  </channel>
</rss>